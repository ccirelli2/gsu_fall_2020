plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1])
plt.show()
help(plt.scatter)
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1],
s=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])
help(plt.scatter)
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1], label='crap')
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1], label=['crap', 'shit'])
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1])
plt.show()
df.groupby('Target')
print(x_pca.head())
x_pca.groupby('Target')
df_grouped = x_pca.groupby('Target')
print(df_grouped.head())
plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)
plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)
colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')
fig, ax = plt.subplots()
ax.set_color_cycle(['r', 'g', 'b'])
ax.margins(0.05)
fig, ax = plt.subplots()
import seaborn as sns
sns.pairplot(x_vars=x_pca[0], y_vars= x_pca[1])
sns.pairplot(x_vars=x_pca[0], y_vars= x_pca[1], data=x_pca)
sns.pairplot(x_vars=["PC1"], y_vars= ["PCA2"], data=x_pca)
x_pca.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'Target']
print(x_pca.head())
sns.pairplot(x_vars=["PC1"], y_vars= ["PCA2"], data=x_pca)
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca)
plt.show()
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue=x_pca['Target'])
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca)
plt.show()
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue='Target')
plt.show()
import numpy as np
import numpy as np
from sklearn.decomposition import KernelPCA
from sklearn.datasets import make_circles
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
x_kpca = kpca.fit_transform(x)
variables = list(df.columns[:-1])
x = df.iloc[: ,0:-1].values
y = df.iloc[:, -1].values
x = StandardScaler().fit_transform(x)
x = pd.DataFrame(x)
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
x_kpca = kpca.fit_transform(x)
pca = PCA()
x_kpca
plot(x_kpca)
plt.plot(x_kpca)
plt.show()
pca = PCA()
print(type(x_kpca))
plt.scatter(x_kpca)
x_kpca.shape()
print(x_kpca)
print(x_kpca.shape())
print(x_kpca.shape
print(x_kpca.shape)
x_kpca = kpca.fit_transform(x)
kpca  = KernelPCA(kernel="rbf", fit_transform=True, gamma=10)
inverse_
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
X_pca = pca.fit_transform(x)
X_pca.head()
print(x_kpca.shape[1])
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
X
plt.scatter(X)
_
X.shape
plt.scatter(x = X[0], y=[1])
plt.scatter(x = X[:,0], y=[:,1])
X[0]
X[1]
X[0,1]
X[:,1]
X[:,0]
len(X[:,0])
plt.scatter(x=X[:, 0], y=[:, 1])
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
'''
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue='Target')
plt.show()
'''
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.2)
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.05)
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
kpca = KernelPCA(kernel='rbf', gamma=15, n_components=1)
x_kpca = kpca.fit_transform(X)
x_kpca.shape
from sklearn.datasets import make_moons
X, y = make_moons(n_samples=500, noise=0.2, random_state=1234)
plt.scatter(X[:,0], y[:1], c=y)
plt.scatter(X[:,0], y[:,1], c=y)
X, y = make_moons(n_samples = 500, noise = 0.02, random_state = 417)
plt.scatter(X[:, 0], X[:, 1], c = y)
plt.show()
dev.off()
# Clear Namespace
rm(list=ls())
# Create Dataset
A <- c(117.1, 121.3, 127.8, 121.9, 117.4, 124.5, 119.5, 115.1)
B <- c(123.5, 125.3, 126.5, 127.9, 122.1, 125.6, 129.8, 117.2)
dat <- data.frame(weight = c(A,B),
company = rep(c("A","B"), each=8))
# Generate Box Plot
boxplot(weight ~ company, data = dat)
# Run Wilcoxon Rank Sum Test
wilcox.test(weight ~ company, data = dat)
head(dat)
rt.data
rm(list=ls())
dev.off(dev.list()["RStudioGD"])
# IMPORT LIBRARIES
library(ggplot2)
library(DBI)
# Instantiate Connection to DB -------------------------
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "yde2xj08jm.database.windows.net",
Database = "SwyfftAnalyticsCentral",
UID = "AnalyticsReadOnly ",
PWD = rstudioapi::askForPassword("Database password"),
port = 1433)
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [PolicyNumber], "Response Time"
FROM [dataiku].[PROFITABILITYCORE_frt_score_api_details_final]')
rt.data
# Clearn Namespace & Plots ------------------------------
rm(list=ls())
dev.off(dev.list()["RStudioGD"])
# IMPORT LIBRARIES
library(ggplot2)
library(DBI)
# Instantiate Connection to DB -------------------------
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "yde2xj08jm.database.windows.net",
Database = "SwyfftAnalyticsCentral",
UID = "AnalyticsReadOnly ",
PWD = rstudioapi::askForPassword("Database password"),
port = 1433)
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [PolicyNumber], "Response Time"
FROM [dataiku].[PROFITABILITYCORE_frt_score_api_details_final]')
rt.data
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
rt.data
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [CLAIM_NBR/RES_NBR]
,[CLAIM_TYPE]
,[Claim_Type_Coverage_Group]
,[COVERAGE]
,[CAUSE_OF_LOSS]
,[PERIL]
,[SUB_PERIL]
,[ACC_DESC]
,[Covid_Flag]
FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT
CAST([CLAIM_NBR/RES_NBR] AS nvarchar(100))
,CAST([CLAIM_TYPE] AS varchar(100))
,CAST([Claim_Type_Coverage_Group] AS varchar(100))
,CAST([COVERAGE] AS varchar(100))
,CAST([CAUSE_OF_LOSS] AS varchar(100))
,CAST([PERIL] AS varchar(100))
,CAST([SUB_PERIL] AS varchar(100))
,CAST([ACC_DESC]AS varchar(250))
,[Covid_Flag]
FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
require(XML)
install.packages('XML')
require(XML)
require(XML)
help(xmlTreeParse)
# Create Step Plot --------------------------------------------------
data("AirPassengers")
air <- AirPassengers
# Create Step Plot --------------------------------------------------
data("AirPassengers")
# Create Step Plot --------------------------------------------------
data("BJsales")
# Create Step Plot --------------------------------------------------
data("BJsales")
# Create Step Plot --------------------------------------------------
data()
# Create Step Plot --------------------------------------------------
data(AirPassengers)
head(AirPassengers)
length(AirPassengers)
seq(length(AirPassengers))
x.vals <- seq(length(AirPassengers))
# Create Step Plot --------------------------------------------------
y.values = data(AirPassengers)
y.vals <- AirPassengers
x.vals <- seq(length(AirPassengers))
plot(x.vals, y.vals)
plot(x.vals, y.vals, type='s')
plot(x.vals, type='hist')
hist(x.vals)
hist(x.vals, bins=10)
hist(x.vals, bins=10)
hist(x.vals, bins=100)
hist(x.vals, bins=5)
warnings()
help(hist)
help(hist, breaks=10)
hist(x.vals, breaks=10)
hist(x.vals, breaks=15)
hist(y.vals, breaks=15)
hist(y.vals, breaks=10)
hist(y.vals, breaks=10)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
my = <- 20; sigma.2 <- 4; set.seed(33)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
my <- 20; sigma.2 <- 4; set.seed(33)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
mu <- 20; sigma.2 <- 4; set.seed(33)
# Clear namespace and plots
rm(list=ls())
dev.off()
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
mu <- 20; sigma.2 <- 4; set.seed(33)
X <- rnomr(100, mu, sqrt(sigma.2))
X <- rnorm(100, mu, sqrt(sigma.2))
hist(X)
X <- rnorm(1000, mu, sqrt(sigma.2))
hist(X)
qqnorm(X)
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) +
1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
log.L <- function(mu.hat = 15, simga.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, sigma.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
X <- rnorm(100, mu, sqrt(sigma.2))
hist(X)    # hist plot
qqnorm(X)  # qq plot
log.L <- function(mu.hat = 15, sigma.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
fit <- mle(log.L)
summary(fit)
f = makeFun(x^2+y~x&y)
library(mosaic)
install.packages(mosaic)
install.packages('mosaic')
library(makeFun)
library(mosaic)
f = makeFun(x^2+y~x&y)
print(f)
g = makeFun(x^2 - y^2 ~x&y)
print(g)
# Plot Objective Function
plotFun(f(x,y)~x&y)
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(0,10), y.lim=range(0,10))
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-10,10), y.lim=range(-10,10))
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10)), filled=FALSE, add=TRUE,
color='red')
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10)), filled=FALSE, add=TRUE, color='red')
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE, add=TRUE, color='red')
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE)
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE, add=TRUE, color='red')
dev.off()
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-2,2), y.lim=range(-2,2), filled=FALSE)
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, filled=FALSE, add=TRUE, color='red')
install.packages("ggmap")
library("ggmap")
data(crime, package="ggmap")
locations <- filter(crime, offense='rape') %>%
select(date, offense, address, lon, lat)
locations <- filter(crime, offense='rape') %>% select(date, offense, address, lon, lat)
# Load Data
data(crime, package="ggmap")
locations <- filter(crime, offense =='rape') %>% select(date, offense, address, lon, lat)
head(crime)
locations <- filter(crime, offense =='rape') %>% select(date, offense, address, lon, lat)
locations <- filter(crime, crime$offense =='rape') %>% select(date, offense, address, lon, lat)
library(dplyr)
# Load Data
data(crime, package="ggmap")
head(crime)
locations <- filter(crime, crime$offense =='rape') %>% select(date, offense, address, lon, lat)
locations
head(locations)
register_google(key=my.key)
setwd("D:/ycData/Dropbox/teaching_this_semester/MSA8020_DataVisualization/2020 fall/Data/")
library("ggmap")
data(crime, package="ggmap")
# subset the data
library(dplyr)
rapes <- filter(crime, offense == "rape") %>%
select(date, offense, address, lon, lat)
# view data
head(rapes)
register_google(key = "your API key")
register_google(key=my.key)
my.key = "AIzaSyAYlABxxPJxY3yRFlBEoqCDIdeDxKD0-Xw"
register_google(key=my.key)
houston_center <- geocode("Houston", "TX")
houston_center <- geocode("Houston, TX")
print(houston_center)_
print(houston_center)
houston_map <- get_map(c(lon=houston_center$lon,
lat=houston_center$lat),
zoom=12, maptype="roadmap")
plt.show()
ggmap(houston_map)
ggmap(houston_map, base_layer=ggplot(data=rapes, aes(x=lon, y=lat)))
ggmap(houston_map, base_layer=ggplot(data=rapes, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
ggmap(houston_map, base_layer=ggplot(data=rapes, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
locations.shape
locations.dim
shape(locations)
describe(locations)
summary(locations)
houston_center <- geocode("Houston, TX")
lon.houston <- houston_center$lon
lat.houston <- houston_center$lat
houston_map <- get_map(c(lon=lon.houston, lat=lat.houston),
zoom=12, maptype="roadmap")
ggmap(houston_map)
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
houston_map <- get_map(c(lon=lon.houston, lat=lat.houston),
zoom=20, maptype="roadmap")
se the map is not big enough'
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
houston_map <- get_map(c(lon=lon.houston, lat=lat.houston),
zoom=5, maptype="roadmap")
ase the map is not big enough'
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
houston_map <- get_map(c(lon=lon.houston, lat=lat.houston),
zoom=10, maptype="roadmap")
'Error: Remove 228 rows, becuase the map is not big enough'
ggmap(houston_map, base_layer=ggplot(data=locations, aes(x=lon, y=lat))) +
geom_point(color = "red", size = 3, alpha = 0.5)
help(get_map)
install.packages("acepack")
install.packages("choroplethrMaps")
require("acepack")
require("choroplethrMaps")
data(gapminder, package = "gapminder")
plotdata <- gapminder %>%
filter(year == 2007) %>%
rename(region = country, value = lifeExp) %>%
mutate(region = tolower(region))
install.packages("gapminder")
require("gapminder")
data(gapminder, package = "gapminder")
plotdata <- gapminder %>%
filter(year == 2007) %>%
rename(region = country, value = lifeExp) %>%
mutate(region = tolower(region))
install.packages("plotly")
library(plotly)
library(dplyr)
data
help(datasets)
help(data(sets))
help(data())
# Load Data
data()
# Load Data
AirPassengers
# Load Data
data()
# Load Data
Nile()
# Load Data
Nile
# Load Data
UCBAdmissions
# Load Data
UCBAdmissions
# Load Data
swiss
# Load Data
dir.data <- "C:\\Users\\chris.cirelli\\Desktop\\repositories\\gsu_fall_2020\\Visualizations\\hw3\\data"
dir.scripts <- "C:\\Users\\chris.cirelli\\Desktop\\repositories\\gsu_fall_2020\\Visualizations\\hw3"
setwd(dir.data)
lr.data <- read.csv("ar_little_rock_2020_04_01.csv")
setwd(dir.scripts)
# Remove Nan
lr.nonan <- na.omit(lr.data)
# Summary
head(lr.nonan)
lr.groupby.veh.sex <- lr.omit.na %>%
group_by(vehicle_type, subject_sex) %>%
summarise(cnt = n())
lr.groupby.veh.sex <- lr.nonan %>%
group_by(vehicle_type, subject_sex) %>%
summarise(cnt = n())
lr.groupby.veh.sex
ggplot and assign it to a varaible'
p1 <- ggplot(data=lr.nonan, aes(x=cnt, y=vehicle_type)) +
geom_point()
p1
p1 <- ggplot(data=lr.groupby.veh.sex, aes(x=cnt, y=vehicle_type)) +
geom_point()
p1
p1 <- ggplot(data=lr.groupby.veh.sex, aes(x=cnt, y=vehicle_type)) +
geom_point() + flip_data()
p1 <- ggplot(data=lr.groupby.veh.sex, aes(x=cnt, y=vehicle_type)) +
geom_point() + coord_flip()
p1
p1 <- ggplot(data=lr.groupby.veh.sex, aes(x=cnt, y=vehicle_type)) +
geom_col() + coord_flip()
p1
# Pass to Plotly
ggplotly(p1)
p1 <- ggplot(data=lr.groupby.veh.sex, aes(x=cnt, y=vehicle_type)) +
geom_col() + coord_flip()
p1
# Pass to Plotly
ggplotly(p1)
plot_ly(data=lr.groupby.veh.sex, x= ~cnt, y= ~vehicle_type)
help(plot_ly)
plot_ly(data=lr.groupby.veh.sex, x= ~cnt, y= ~vehicle_type, type='bar')
help(plot_ly)
dev.off()
install.packages(shiny)
install.packages("shiny")
install.packages("shiny")
