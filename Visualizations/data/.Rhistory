ax.set_xlabel(‘Principal Component 1’)
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_title('2 component PCA')
targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'
colors = ['r', 'g', 'b']
colors = ['r', 'g', 'b']
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
ax.legend(targets)
ax.grid()
targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']
colors = ['r', 'g', 'b']
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
ax.legend(targets)
ax.grid()
plt.show()
fig = plt.figure()
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_title('2 component PCA')
targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']
colors = ['r', 'g', 'b']
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
ax.legend(targets)
ax.grid()
plt.show()
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
ax.legend(targets)
ax.grid()
plt.show()
fig = plt.figure()
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_title('2 component PCA')
targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']
colors = ['r', 'g', 'b']
for target, color in zip(targets,colors):
indicesToKeep = x_pca[‘target’] == target
ax.scatter(x_pca.loc[indicesToKeep, 'PC1']
, x_pca.loc[indicesToKeep, 'PC2']
, c = color
, s = 50)
ax.legend(targets)
ax.grid()
plt.scatter(x = x_pca[:, 0], y = x_pca[:, 1])
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1])
plt.show()
help(plt.scatter())
help(plt.scatter)
ponents ------------------------
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1],
c=['r', 'g', 'b'])
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1])
plt.show()
help(plt.scatter)
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1],
s=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])
help(plt.scatter)
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1], label='crap')
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1], label=['crap', 'shit'])
plt.show()
plt.scatter(x = x_pca.iloc[:, 0], y = x_pca.iloc[:, 1])
plt.show()
df.groupby('Target')
print(x_pca.head())
x_pca.groupby('Target')
df_grouped = x_pca.groupby('Target')
print(df_grouped.head())
plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)
plt.rcParams.update(pd.tools.plotting.mpl_stylesheet)
colors = pd.tools.plotting._get_standard_colors(len(groups), color_type='random')
fig, ax = plt.subplots()
ax.set_color_cycle(['r', 'g', 'b'])
ax.margins(0.05)
fig, ax = plt.subplots()
import seaborn as sns
sns.pairplot(x_vars=x_pca[0], y_vars= x_pca[1])
sns.pairplot(x_vars=x_pca[0], y_vars= x_pca[1], data=x_pca)
sns.pairplot(x_vars=["PC1"], y_vars= ["PCA2"], data=x_pca)
x_pca.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'Target']
print(x_pca.head())
sns.pairplot(x_vars=["PC1"], y_vars= ["PCA2"], data=x_pca)
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca)
plt.show()
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue=x_pca['Target'])
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca)
plt.show()
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue='Target')
plt.show()
import numpy as np
import numpy as np
from sklearn.decomposition import KernelPCA
from sklearn.datasets import make_circles
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
x_kpca = kpca.fit_transform(x)
variables = list(df.columns[:-1])
x = df.iloc[: ,0:-1].values
y = df.iloc[:, -1].values
x = StandardScaler().fit_transform(x)
x = pd.DataFrame(x)
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
x_kpca = kpca.fit_transform(x)
pca = PCA()
x_kpca
plot(x_kpca)
plt.plot(x_kpca)
plt.show()
pca = PCA()
print(type(x_kpca))
plt.scatter(x_kpca)
x_kpca.shape()
print(x_kpca)
print(x_kpca.shape())
print(x_kpca.shape
print(x_kpca.shape)
x_kpca = kpca.fit_transform(x)
kpca  = KernelPCA(kernel="rbf", fit_transform=True, gamma=10)
inverse_
kpca  = KernelPCA(kernel="rbf", fit_inverse_transform=True, gamma=10)
X_pca = pca.fit_transform(x)
X_pca.head()
print(x_kpca.shape[1])
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
X
plt.scatter(X)
_
X.shape
plt.scatter(x = X[0], y=[1])
plt.scatter(x = X[:,0], y=[:,1])
X[0]
X[1]
X[0,1]
X[:,1]
X[:,0]
len(X[:,0])
plt.scatter(x=X[:, 0], y=[:, 1])
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
'''
sns.pairplot(x_vars=["PC1"], y_vars=["PC2"], data=x_pca, hue='Target')
plt.show()
'''
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
sns.scatterplot(x=X[:,1], y=X[:,0])
plt.show()
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.2)
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.05)
plt.scatter(x=X[:,0], y=X[:,1])
plt.show()
X, _ = make_circles(n_samples= 1000, random_state=1, noise=0.1, factor=0.1)
sns.scatterplot(x=X[:,0], y=X[:,1])
plt.show()
kpca = KernelPCA(kernel='rbf', gamma=15, n_components=1)
x_kpca = kpca.fit_transform(X)
x_kpca.shape
from sklearn.datasets import make_moons
X, y = make_moons(n_samples=500, noise=0.2, random_state=1234)
plt.scatter(X[:,0], y[:1], c=y)
plt.scatter(X[:,0], y[:,1], c=y)
X, y = make_moons(n_samples = 500, noise = 0.02, random_state = 417)
plt.scatter(X[:, 0], X[:, 1], c = y)
plt.show()
dev.off()
# Clear Namespace
rm(list=ls())
# Create Dataset
A <- c(117.1, 121.3, 127.8, 121.9, 117.4, 124.5, 119.5, 115.1)
B <- c(123.5, 125.3, 126.5, 127.9, 122.1, 125.6, 129.8, 117.2)
dat <- data.frame(weight = c(A,B),
company = rep(c("A","B"), each=8))
# Generate Box Plot
boxplot(weight ~ company, data = dat)
# Run Wilcoxon Rank Sum Test
wilcox.test(weight ~ company, data = dat)
head(dat)
rt.data
rm(list=ls())
dev.off(dev.list()["RStudioGD"])
# IMPORT LIBRARIES
library(ggplot2)
library(DBI)
# Instantiate Connection to DB -------------------------
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "yde2xj08jm.database.windows.net",
Database = "SwyfftAnalyticsCentral",
UID = "AnalyticsReadOnly ",
PWD = rstudioapi::askForPassword("Database password"),
port = 1433)
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [PolicyNumber], "Response Time"
FROM [dataiku].[PROFITABILITYCORE_frt_score_api_details_final]')
rt.data
# Clearn Namespace & Plots ------------------------------
rm(list=ls())
dev.off(dev.list()["RStudioGD"])
# IMPORT LIBRARIES
library(ggplot2)
library(DBI)
# Instantiate Connection to DB -------------------------
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "yde2xj08jm.database.windows.net",
Database = "SwyfftAnalyticsCentral",
UID = "AnalyticsReadOnly ",
PWD = rstudioapi::askForPassword("Database password"),
port = 1433)
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [PolicyNumber], "Response Time"
FROM [dataiku].[PROFITABILITYCORE_frt_score_api_details_final]')
rt.data
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
rt.data
rt.data <- dbGetQuery(con, '
SELECT * FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT [CLAIM_NBR/RES_NBR]
,[CLAIM_TYPE]
,[Claim_Type_Coverage_Group]
,[COVERAGE]
,[CAUSE_OF_LOSS]
,[PERIL]
,[SUB_PERIL]
,[ACC_DESC]
,[Covid_Flag]
FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
# Load Data ---------------------------------------------
rt.data <- dbGetQuery(con, '
SELECT
CAST([CLAIM_NBR/RES_NBR] AS nvarchar(100))
,CAST([CLAIM_TYPE] AS varchar(100))
,CAST([Claim_Type_Coverage_Group] AS varchar(100))
,CAST([COVERAGE] AS varchar(100))
,CAST([CAUSE_OF_LOSS] AS varchar(100))
,CAST([PERIL] AS varchar(100))
,CAST([SUB_PERIL] AS varchar(100))
,CAST([ACC_DESC]AS varchar(250))
,[Covid_Flag]
FROM [dbo].[chris_core_claims_reclassification_manual_with_claim_type]')
require(XML)
install.packages('XML')
require(XML)
require(XML)
help(xmlTreeParse)
# Create Step Plot --------------------------------------------------
data("AirPassengers")
air <- AirPassengers
# Create Step Plot --------------------------------------------------
data("AirPassengers")
# Create Step Plot --------------------------------------------------
data("BJsales")
# Create Step Plot --------------------------------------------------
data("BJsales")
# Create Step Plot --------------------------------------------------
data()
# Create Step Plot --------------------------------------------------
data(AirPassengers)
head(AirPassengers)
length(AirPassengers)
seq(length(AirPassengers))
x.vals <- seq(length(AirPassengers))
# Create Step Plot --------------------------------------------------
y.values = data(AirPassengers)
y.vals <- AirPassengers
x.vals <- seq(length(AirPassengers))
plot(x.vals, y.vals)
plot(x.vals, y.vals, type='s')
plot(x.vals, type='hist')
hist(x.vals)
hist(x.vals, bins=10)
hist(x.vals, bins=10)
hist(x.vals, bins=100)
hist(x.vals, bins=5)
warnings()
help(hist)
help(hist, breaks=10)
hist(x.vals, breaks=10)
hist(x.vals, breaks=15)
hist(y.vals, breaks=15)
hist(y.vals, breaks=10)
hist(y.vals, breaks=10)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
my = <- 20; sigma.2 <- 4; set.seed(33)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
my <- 20; sigma.2 <- 4; set.seed(33)
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
mu <- 20; sigma.2 <- 4; set.seed(33)
# Clear namespace and plots
rm(list=ls())
dev.off()
# Step 1 - create a sample from a normal distributoin with known mu and sigma2
mu <- 20; sigma.2 <- 4; set.seed(33)
X <- rnomr(100, mu, sqrt(sigma.2))
X <- rnorm(100, mu, sqrt(sigma.2))
hist(X)
X <- rnorm(1000, mu, sqrt(sigma.2))
hist(X)
qqnorm(X)
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) +
1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, simga.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
log.L <- function(mu.hat = 15, simga.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
# Step 2 - Define L According to equation 9.2, which is for the normal distribution
log.L <- function(mu.hat = 15, sigma.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
X <- rnorm(100, mu, sqrt(sigma.2))
hist(X)    # hist plot
qqnorm(X)  # qq plot
log.L <- function(mu.hat = 15, sigma.2.hat = 6){
n <- length(X)
n/2 * log(2 * pi * sigma.2.hat) + 1/2 * sum((X - mu.hat)^2 / sigma.2.hat)
}
# Step3 - Use MLE Function from the Stats Packages
library(stats4)
(fit <- mle(log.L))
fit <- mle(log.L)
summary(fit)
f = makeFun(x^2+y~x&y)
library(mosaic)
install.packages(mosaic)
install.packages('mosaic')
library(makeFun)
library(mosaic)
f = makeFun(x^2+y~x&y)
print(f)
g = makeFun(x^2 - y^2 ~x&y)
print(g)
# Plot Objective Function
plotFun(f(x,y)~x&y)
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(0,10), y.lim=range(0,10))
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-10,10), y.lim=range(-10,10))
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10)), filled=FALSE, add=TRUE,
color='red')
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10)), filled=FALSE, add=TRUE, color='red')
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE, add=TRUE, color='red')
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE)
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, x.lim=range(-10,10), y.lim=range(-10,10), filled=FALSE, add=TRUE, color='red')
dev.off()
# Plot Objective Function
plotFun(f(x,y)~x&y, x.lim=range(-2,2), y.lim=range(-2,2), filled=FALSE)
# Not Plot the Constraint
plotFun(g(x,y)~x&y, levels=1, filled=FALSE, add=TRUE, color='red')
install.packages("carData") ## only need to run this once to install this package to your computer.
require("carData") ## need to run this every time you start a new R session, to load it to the current session
install.packages("readr") ## to import data
require("readr")
install.packages("dplyr") ## for data manipulation
install.packages("dplyr")
## You will be asked: Do you want to install from sources the packages which need compilation? (Yes/no/cancel)
## type no, then hit enter
require("dplyr")
data(Salaries, package="carData") ## if data is contained in a package
data(Salaries, package="carData") ## if data is contained in a package
data(Salaries, package="carData") ## if data is contained in a package
rm(list=ls())
install.packages("dplyr")
install.packages("dplyr")
rm(list=ls())
require("carData") ## need to run this every time you start a new R session, to load it to the current session
require("readr")
## You will be asked: Do you want to install from sources the packages which need compilation? (Yes/no/cancel)
## type no, then hit enter
require("dplyr")
data(Salaries, package="carData") ## if data is contained in a package
head(carData)
library(readr)
## data can be otained here: https://rkabacoff.github.io/datavis/Data.html#Salaries
# import data from a comma delimited file
Salaries <- read_csv("salaries.csv")
# import data from a tab delimited file
set.wd('C:\Users\chris.cirelli\Desktop\repositories\gsu_fall_2020\Visualizations\data')
# import data from a tab delimited file
set.wd(r'C:\Users\chris.cirelli\Desktop\repositories\gsu_fall_2020\Visualizations\data')
# import data from a tab delimited file
set.wd("C:\Users\chris.cirelli\Desktop\repositories\gsu_fall_2020\Visualizations\data")
# import data from a tab delimited file
set.wd('C:\\Users\\chris.cirelli\\Desktop\\repositories\\gsu_fall_2020\\Visualizations\\data')
# import data from a tab delimited file
setwd('C:\\Users\\chris.cirelli\\Desktop\\repositories\\gsu_fall_2020\\Visualizations\\data')
Salaries <- read_tsv("salaries.txt")
Salaries <- read_tsv("salaries.csv")
library(haven)
# import data from Stata
Salaries <- read_dta("salaries.dta")
str(Salaries)
colnames(Salaries)
dim(Salaries)
## after you import a data into R, the first thing is always to double check to make sure it's correctely imported and understand the data structure
Salaries
# import data from an Excel workbook
Salaries <- read_excel("salaries.xlsx", sheet=1)
library(readxl)
# import data from an Excel workbook
Salaries <- read_excel("salaries.xlsx", sheet=1)
## after you import a data into R, the first thing is always to double check to make sure it's correctely imported and understand the data structure
str(Salaries)
colnames(Salaries)
dim(Salaries)
head(Salaries,5)
View(Salaries)
## selecting variables
library(dplyr)
colnames(starwars)
dim(starwars)
# keep the variables name, height, and gender
newdata <- select(starwars, name, height, gender)
newdata <- select(starwars,c(name,height,gender))
newdata
# keep the variables name and all variables
# between mass and species inclusive
newdata <- select(starwars, name, mass:species)
# keep all variables except birth_year and gender
newdata <- select(starwars, -birth_year, -gender)
newdata <- select(starwars,-c(name))
# select females
newdata <- filter(starwars, gender == "female")
# select females that are from Alderaan
newdata <- filter(starwars, gender == "female" & homeworld == "Alderaan")
# convert height in centimeters to inches,
# and mass in kilograms to pounds
newdata <- mutate(starwars,height = height * 0.394, mass   = mass   * 2.205)
# calculate the mean height for women by species
newdata <- filter(starwars,gender == "female")
newdata <- filter(starwars,gender == "feminine")
newdata <- group_by(species)
newdata <- summarize(newdata,mean_ht = mean(height, na.rm = TRUE))
newdata
